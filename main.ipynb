{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Lee el archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'CancerDataset.csv'  # Reemplaza con el nombre de tu archivo CSV\n",
    "data = pd.read_csv(nombre_archivo)\n",
    "\n",
    "# Elimina la primera columna (asumiendo que no es necesaria)\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Extrae los datos de y (segunda columna) como una lista\n",
    "y_data = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Extrae los datos de x (resto de las columnas) como una matriz\n",
    "x_data = data.iloc[:, 1:].values\n",
    "\n",
    "# # Imprime los resultados para verificar\n",
    "# print(\"Datos de y:\")\n",
    "# print(y_data)\n",
    "y_data=np.array(y_data)\n",
    "# print(\"\\nDatos de x:\")\n",
    "# print(x_data)\n",
    "x_data=np.array(x_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir los valores de \"y\" a M y B a 1 y 0, respectivamente\n",
    "\n",
    "y_data = [1 if x == 'M' else 0 for x in y_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de elementos iguales a Maligno: 212\n",
      "Cantidad de elementos iguales a Benigno: 357\n"
     ]
    }
   ],
   "source": [
    "conteo_1 = y_data.count(1)\n",
    "conteo_0 = y_data.count(0)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(\"Cantidad de elementos iguales a Maligno:\", conteo_1)\n",
    "print(\"Cantidad de elementos iguales a Benigno:\", conteo_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redución de características de X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando componentes que nos permitan mantener el 90% de la Varianza Explicada\n",
    "pca = PCA(n_components=0.9)\n",
    "pca.fit(x_data)\n",
    "X_reduced = pca.transform(x_data)\n",
    "X_reduced\n",
    "\n",
    "## en esta parte conectamos el vectro caracteristico con su tipo\n",
    "\n",
    "dataset=[]\n",
    "j=0\n",
    "for i in X_reduced:\n",
    "  dataset.append([i,y_data[j]])\n",
    "  j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#  'dataset' es el conjunto de datos\n",
    "np.random.seed(42)\n",
    "\n",
    "np.random.shuffle(dataset)  # Mezclamos el dataset para asegurarnos de que los datos estén en orden aleatorio\n",
    "\n",
    "n = len(dataset)\n",
    "n_train = int(0.7 * n)\n",
    "n_test = n - n_train\n",
    "\n",
    "# Dividir el dataset\n",
    "train_data = dataset[:n_train]\n",
    "test_data = dataset[n_train:]\n",
    "\n",
    "# Dividir la data de entrenamiento\n",
    "x_train = np.array([sample[0] for sample in train_data])\n",
    "y_train = np.array([sample[1] for sample in train_data])\n",
    "\n",
    "# Dividir la data de prueba\n",
    "x_test = np.array([sample[0] for sample in test_data])\n",
    "y_test = np.array([sample[1] for sample in test_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar los datos de train y test en archivos .txt\n",
    "\n",
    "Estos archivos ayudaran paar que se pueda leer despues en el archivo .cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Guarda la matriz en un archivo de texto (CSV)\n",
    "np.savetxt('./data_train/x_train.txt', x_train, delimiter=',', fmt='%f')\n",
    "np.savetxt('./data_train/y_train.txt', y_train, delimiter=',', fmt='%d')\n",
    "np.savetxt('./data_test/x_test.txt', x_test, delimiter=',', fmt='%f')\n",
    "np.savetxt('./data_test/y_test.txt', y_test, delimiter=',', fmt='%d')\n",
    "\n",
    "# Imprime un mensaje de confirmación\n",
    "print(\"Datos guardados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programa C++ ejecutado exitosamente. Resultados en 'output_sigmoid/predictions1_3.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_sigmoid/predictions1_2.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_sigmoid/predictions3_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_sigmoid/predictions4_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_sigmoid/predictions10_8.txt'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta al archivo C++\n",
    "ruta_cpp = \"cplusplus/sigmoid.cpp\"  # Ajusta la ruta según tu estructura de carpetas\n",
    "\n",
    "# Configuraciones y nombres de archivo de salida\n",
    "configuraciones = [\n",
    "    (\"output_sigmoid/predictions1_3.txt\", 1, 3),\n",
    "    (\"output_sigmoid/predictions1_2.txt\", 1, 2),\n",
    "    (\"output_sigmoid/predictions3_6.txt\", 3, 6),\n",
    "    (\"output_sigmoid/predictions4_6.txt\", 4, 6),\n",
    "    (\"output_sigmoid/predictions10_8.txt\", 10, 8),\n",
    "]\n",
    "\n",
    "for archivo_salida, capas_ocultas, neuronas_por_capa in configuraciones:\n",
    "    # Compila el programa C++\n",
    "    compilacion_exitosa = subprocess.run([\"g++\", ruta_cpp, \"-o\", \"cplusplus/sigmoid\"])\n",
    "\n",
    "    if compilacion_exitosa.returncode == 0:\n",
    "        # Ejecuta el programa compilado y redirige la salida al archivo correspondiente\n",
    "        with open(archivo_salida, \"w\") as salida_archivo:\n",
    "            subprocess.run(\n",
    "                [\"./cplusplus/sigmoid\"],\n",
    "                stdout=salida_archivo,\n",
    "                cwd=\"output_sigmoid\",\n",
    "                input=f\"{capas_ocultas}\\n{neuronas_por_capa}\\n{X_reduced.shape[1]}\\n\",  # Pasa las configuraciones al programa\n",
    "                text=True,  # Trata los datos de entrada y salida como texto\n",
    "            )\n",
    "        print(f\"Programa C++ ejecutado exitosamente. Resultados en '{archivo_salida}'\")\n",
    "    else:\n",
    "        print(\"Error de compilación. Verifica la existencia del archivo C++ y el compilador g++.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programa C++ ejecutado exitosamente. Resultados en 'output_tanh/predictions1_3.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_tanh/predictions2_4.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_tanh/predictions3_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_tanh/predictions4_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_tanh/predictions10_8.txt'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta al archivo C++\n",
    "ruta_cpp = \"cplusplus/tanh.cpp\"  # Ajusta la ruta según tu estructura de carpetas\n",
    "\n",
    "# Configuraciones y nombres de archivo de salida\n",
    "configuraciones = [\n",
    "    (\"output_tanh/predictions1_3.txt\", 1, 3),\n",
    "    (\"output_tanh/predictions2_4.txt\", 2, 4),\n",
    "    (\"output_tanh/predictions3_6.txt\", 3, 6),\n",
    "    (\"output_tanh/predictions4_6.txt\", 4, 6),\n",
    "    (\"output_tanh/predictions10_8.txt\", 10, 8),\n",
    "]\n",
    "\n",
    "for archivo_salida, capas_ocultas, neuronas_por_capa in configuraciones:\n",
    "    # Compila el programa C++\n",
    "    compilacion_exitosa = subprocess.run([\"g++\", ruta_cpp, \"-o\", \"cplusplus/tanh\"])\n",
    "\n",
    "    if compilacion_exitosa.returncode == 0:\n",
    "        # Ejecuta el programa compilado y redirige la salida al archivo correspondiente\n",
    "        with open(archivo_salida, \"w\") as salida_archivo:\n",
    "            subprocess.run(\n",
    "                [\"./cplusplus/tanh\"],\n",
    "                stdout=salida_archivo,\n",
    "                cwd=\"output_tanh\",\n",
    "                input=f\"{capas_ocultas}\\n{neuronas_por_capa}\\n{X_reduced.shape[1]}\\n\",  # Pasa las configuraciones al programa\n",
    "                text=True,  # Trata los datos de entrada y salida como texto\n",
    "            )\n",
    "        print(f\"Programa C++ ejecutado exitosamente. Resultados en '{archivo_salida}'\")\n",
    "    else:\n",
    "        print(\"Error de compilación. Verifica la existencia del archivo C++ y el compilador g++.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programa C++ ejecutado exitosamente. Resultados en 'output_relu/predictions1_3.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_relu/predictions2_4.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_relu/predictions3_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_relu/predictions4_6.txt'\n",
      "Programa C++ ejecutado exitosamente. Resultados en 'output_relu/predictions10_8.txt'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Ruta al archivo C++\n",
    "ruta_cpp = \"cplusplus/relu.cpp\"  # Ajusta la ruta según tu estructura de carpetas\n",
    "\n",
    "# Configuraciones y nombres de archivo de salida\n",
    "configuraciones = [\n",
    "    (\"output_relu/predictions1_3.txt\", 1, 3),\n",
    "    (\"output_relu/predictions2_4.txt\", 2, 4),\n",
    "    (\"output_relu/predictions3_6.txt\", 3, 6),\n",
    "    (\"output_relu/predictions4_6.txt\", 4, 6),\n",
    "    (\"output_relu/predictions10_8.txt\", 10, 8),\n",
    "]\n",
    "\n",
    "for archivo_salida, capas_ocultas, neuronas_por_capa in configuraciones:\n",
    "    # Compila el programa C++\n",
    "    compilacion_exitosa = subprocess.run([\"g++\", ruta_cpp, \"-o\", \"cplusplus/relu\"])\n",
    "\n",
    "    if compilacion_exitosa.returncode == 0:\n",
    "        # Ejecuta el programa compilado y redirige la salida al archivo correspondiente\n",
    "        with open(archivo_salida, \"w\") as salida_archivo:\n",
    "            subprocess.run(\n",
    "                [\"./cplusplus/relu\"],\n",
    "                stdout=salida_archivo,\n",
    "                cwd=\"output_relu\",\n",
    "                input=f\"{capas_ocultas}\\n{neuronas_por_capa}\\n{X_reduced.shape[1]}\\n\",  # Pasa las configuraciones al programa\n",
    "                text=True,  # Trata los datos de entrada y salida como texto\n",
    "            )\n",
    "        print(f\"Programa C++ ejecutado exitosamente. Resultados en '{archivo_salida}'\")\n",
    "    else:\n",
    "        print(\"Error de compilación. Verifica la existencia del archivo C++ y el compilador g++.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision\n",
    "Percion del test con lo obtenido en la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_archivo_y_convertir_a_enteros(ruta_archivo):\n",
    "    with open(ruta_archivo, \"r\") as archivo:\n",
    "        lineas = [linea.strip() for linea in archivo.readlines()]\n",
    "\n",
    "    # Convierte las listas de cadenas a listas de enteros\n",
    "    datos_enteros = [int(valor) for elemento in lineas for valor in elemento.split(\",\")]\n",
    "\n",
    "    return datos_enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso en Tanh\n",
    "ruta_archivo_ejemplo = \"output_tanh/predictions1_3.txt\"\n",
    "y_tanh_1_3 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_tanh/predictions2_4.txt\"\n",
    "y_tanh_2_4 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_tanh/predictions3_6.txt\"\n",
    "y_tanh_3_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_tanh/predictions4_6.txt\"\n",
    "y_tanh_4_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_tanh/predictions10_8.txt\"\n",
    "y_tanh_10_8 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso en sigmoid\n",
    "ruta_archivo_ejemplo = \"output_sigmoid/predictions1_2.txt\"\n",
    "y_sigmoid_1_2 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_sigmoid/predictions1_3.txt\"\n",
    "y_sigmoid_1_3 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_sigmoid/predictions3_6.txt\"\n",
    "y_sigmoid_3_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_sigmoid/predictions4_6.txt\"\n",
    "y_sigmoid_4_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_sigmoid/predictions10_8.txt\"\n",
    "y_sigmoid_10_8 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uso en relu\n",
    "ruta_archivo_ejemplo = \"output_relu/predictions1_3.txt\"\n",
    "y_relu_1_2 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_relu/predictions2_4.txt\"\n",
    "y_relu_1_3 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_relu/predictions3_6.txt\"\n",
    "y_relu_3_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_relu/predictions4_6.txt\"\n",
    "y_relu_4_6 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)\n",
    "ruta_archivo_ejemplo = \"output_relu/predictions10_8.txt\"\n",
    "y_relu_10_8 = leer_archivo_y_convertir_a_enteros(ruta_archivo_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh\n",
    "precisión con la función de activación Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"data_test/y_test.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision con la funcion tanh con 1 capa y 3 neuronas por capa 0.862167255961745\n",
      "precision con la funcion tanh con 2 capas y 4 neuronas por capa 0.862167255961745\n",
      "precision con la funcion tanh con 3 capas y 6 neuronas por capa 0.8674463937621831\n",
      "precision con la funcion tanh con 4 capas y 6 neuronas por capa 0.8536542993534353\n",
      "precision con la funcion tanh con 10 capas y 8 neuronas por capa 0.33518005540166207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"precision con la funcion tanh con 1 capa y 3 neuronas por capa\", precision_score(y_test,y_tanh_1_3,average='weighted'))\n",
    "print(\"precision con la funcion tanh con 2 capas y 4 neuronas por capa\", precision_score(y_test,y_tanh_2_4,average='weighted'))\n",
    "print(\"precision con la funcion tanh con 3 capas y 6 neuronas por capa\", precision_score(y_test,y_tanh_3_6,average='weighted'))\n",
    "print(\"precision con la funcion tanh con 4 capas y 6 neuronas por capa\", precision_score(y_test,y_tanh_4_6,average='weighted'))\n",
    "print(\"precision con la funcion tanh con 10 capas y 8 neuronas por capa\", precision_score(y_test,y_tanh_10_8,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision con la funcion sigmoid con 1 capa y 2 neuronas por capa 0.8589668025997197\n",
      "precision con la funcion sigmoid con 1 capa y 3 neuronas por capa 0.8640113798008535\n",
      "precision con la funcion sigmoid con 3 capas y 6 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion sigmoid con 4 capas y 6 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion sigmoid con 10 capas y 8 neuronas por capa 0.33518005540166207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"precision con la funcion sigmoid con 1 capa y 2 neuronas por capa\", precision_score(y_test,y_sigmoid_1_2,average='weighted'))\n",
    "print(\"precision con la funcion sigmoid con 1 capa y 3 neuronas por capa\", precision_score(y_test,y_sigmoid_1_3,average='weighted'))\n",
    "print(\"precision con la funcion sigmoid con 3 capas y 6 neuronas por capa\", precision_score(y_test,y_sigmoid_3_6,average='weighted'))\n",
    "print(\"precision con la funcion sigmoid con 4 capas y 6 neuronas por capa\", precision_score(y_test,y_sigmoid_4_6,average='weighted'))\n",
    "print(\"precision con la funcion sigmoid con 10 capas y 8 neuronas por capa\", precision_score(y_test,y_sigmoid_10_8,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision con la funcion relu con 1 capa y 2 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion relu con 1 capa y 3 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion relu con 3 capas y 6 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion relu con 4 capas y 6 neuronas por capa 0.33518005540166207\n",
      "precision con la funcion relu con 10 capas y 8 neuronas por capa 0.33518005540166207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/envs/mainds/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"precision con la funcion relu con 1 capa y 2 neuronas por capa\", precision_score(y_test,y_relu_1_2,average='weighted'))\n",
    "print(\"precision con la funcion relu con 1 capa y 3 neuronas por capa\", precision_score(y_test,y_relu_1_3,average='weighted'))\n",
    "print(\"precision con la funcion relu con 3 capas y 6 neuronas por capa\", precision_score(y_test,y_relu_3_6,average='weighted'))\n",
    "print(\"precision con la funcion relu con 4 capas y 6 neuronas por capa\", precision_score(y_test,y_relu_4_6,average='weighted'))\n",
    "print(\"precision con la funcion relu con 10 capas y 8 neuronas por capa\", precision_score(y_test,y_relu_10_8,average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
